{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis (Positive or Negative)\n",
        "from transformers import pipeline #use for huggingface\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "result = classifier(\"I was so not happy with the last Mission Impossible Movie\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "pHsaMKVcGX7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task = \"sentiment-analysis\")(\"I was confused with the Barbie Movie\")"
      ],
      "metadata": {
        "id": "IcXK4UDjHAbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task = \"sentiment-analysis\")\\\n",
        "                                      (\"Everyday lots of LLMs papers are published about LLMs Evlauation. \\\n",
        "                                      Lots of them Looks very Promising. \\\n",
        "                                      I am not sure if we CAN actually Evaluate LLMs. \\\n",
        "                                      There is still lots to do.\\\n",
        "                                      Don't you think?\")"
      ],
      "metadata": {
        "id": "yP6UuSiuHCTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task = \"sentiment-analysis\", model=\"facebook/bart-large-mnli\")\\\n",
        "                                      (\"Everyday lots of LLMs papers are published about LLMs Evlauation. \\\n",
        "                                      Lots of them Looks very Promising. \\\n",
        "                                      I am not sure if we CAN actually Evaluate LLMs. \\\n",
        "                                      There is still lots to do.\\\n",
        "                                      Don't you think?\")\n"
      ],
      "metadata": {
        "id": "IE9ywrybHkCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(task = \"sentiment-analysis\")\n",
        "\n",
        "task_list = [\"I really like Autoencoders, best models for Anomaly Detection\", \\\n",
        "            \"I am not sure if we CAN actually Evaluate LLMs.\", \\\n",
        "            \"PassiveAgressive is the name of a Linear Regression Model that so many people do not know.\",\\\n",
        "            \"I hate long Meetings.\"]\n",
        "classifier(task_list)"
      ],
      "metadata": {
        "id": "AcmtyyFYHoPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(task = \"sentiment-analysis\", model = \"SamLowe/roberta-base-go_emotions\")\n",
        "\n",
        "task_list = [\"I really like Autoencoders, best models for Anomaly Detection\", \\\n",
        "            \"I am not sure if we CAN actually Evaluate LLMs.\", \\\n",
        "            \"PassiveAgressive is the name of a Linear Regression Model that so many people do not know. It is pretty funny name for a Regression Model.\",\\\n",
        "            \"I hate long Meetings.\"]\n",
        "classifier(task_list)"
      ],
      "metadata": {
        "id": "faSAzRHRHrVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Generation\n",
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\", model=\"distilbert/distilgpt2\")\n",
        "generated_text = text_generator(\"Today is a rainy day in London\",\n",
        "                                truncation=True,\n",
        "                                num_return_sequences = 2)\n",
        "print(\"Generated_text:\\n \", generated_text[0]['generated_text'])"
      ],
      "metadata": {
        "id": "-uZeBWMykUO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question Answering\n",
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\")\n",
        "question = \"What is my job?\"\n",
        "context = \"I am developing Generative AI with Python.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "id": "rvQ0igpPlh6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "IUWiArKBmf1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "or1I3dOemv2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenization_model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenization = AutoTokenizer.from_pretrained(tokenization_model)\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=tokenization)\n",
        "res = classifier(\"I was so not happy with the Barbie Movie\")\n",
        "print(res)"
      ],
      "metadata": {
        "id": "cgGg23Bxmvu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# Load a pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Example text\n",
        "text = \"I was so not happy with the Barbie Movie\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "id": "8SJqrBwnmvsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to input IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"Input IDs:\", input_ids)"
      ],
      "metadata": {
        "id": "peFS6oEGmvpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the text (tokenization + converting to input IDs)\n",
        "encoded_input = tokenizer(text)\n",
        "print(\"Encoded Input:\", encoded_input)\n"
      ],
      "metadata": {
        "id": "_Gj2OFJqm6OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the text\n",
        "decoded_output = tokenizer.decode(input_ids)\n",
        "print(\"Decode Output: \", decoded_output)"
      ],
      "metadata": {
        "id": "M3bFBQXsm6Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load a pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Example text\n",
        "text = \"I was so not happy with the Barbie Movie\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Convert tokens to input IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"Input IDs:\", input_ids)\n",
        "\n",
        "# Encode the text (tokenization + converting to input IDs)\n",
        "encoded_input = tokenizer(text)\n",
        "print(\"Encoded Input:\", encoded_input)\n",
        "\n",
        "# Decode the text\n",
        "decoded_output = tokenizer.decode(input_ids)\n",
        "print(\"Decode Output: \", decoded_output)"
      ],
      "metadata": {
        "id": "BFewqp6em6I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Summarization using HuggingFace\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is transforming industries worldwide.\n",
        "From healthcare and finance to transportation and education, AI is enabling\n",
        "automation, efficiency, and innovative solutions. Natural Language Processing (NLP),\n",
        "a subfield of AI, allows machines to understand, interpret, and generate human language.\n",
        "This advancement powers applications such as chatbots, virtual assistants,\n",
        "machine translation, and sentiment analysis.\n",
        "Despite its benefits, AI also raises ethical concerns about bias, privacy, and job displacement.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary\n",
        "summary = summarizer(text, max_length=80, min_length=30, do_sample=False)\n",
        "\n",
        "print(\"Original Text:\\n\", text)\n",
        "print(\"\\nSummary:\\n\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "cah8Ps-3pXkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation\n",
        "from transformers import pipeline\n",
        "generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "translation = generator(\"translate English to German: How are you?\", max_length=40)\n",
        "print(\"\\nTranslation (ENâ†’DE):\\n\", translation[0]['generated_text'])"
      ],
      "metadata": {
        "id": "uZrcuYacqDwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill-Mask using HuggingFace\n",
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "\n",
        "result = unmasker(\"I love to play [MASK] in the evening.\")\n",
        "for r in result:\n",
        "    print(f\"{r['sequence']} (score: {r['score']:.4f})\")"
      ],
      "metadata": {
        "id": "UBXDNG8TrBkA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}